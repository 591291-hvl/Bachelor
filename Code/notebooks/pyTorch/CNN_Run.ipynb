{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\47472\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "#other libraries\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# import random\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "#torch specific\n",
    "import torch\n",
    "import torchvision as torchv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importerer spaleron og micro svarte hull data\n",
    "\n",
    "module_path = str(Path.cwd().parents[0].parents[0] / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "# from plotCreator import *\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"bh\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"sph\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50, 50, 3)\n",
      "(15000, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(bhArray.shape)\n",
    "print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi slår sammen dataene for å ha et samlet datasett som kjører gjennom modellen\n",
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeler tabelle med 1 og 0 (0 = svart hull, 1 = spahleron)\n",
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75% av datasettet havner i trainData, 25% havner i testData, \n",
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gjør det om til en tensor fra numpy array. Vi gjør dette for at at dataene skal være lagret på GPU en istedet for en liste som er lagret på CPUen \n",
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor datasett \n",
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her kommer modellen inn XD \n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "\n",
    "        super(ConvModel, self).__init__()\n",
    "        # 2 cov lag blir opprette. Bildene har x, y og z verdi. \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(3*3*256, 128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x) #to activate function above\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x,3)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             448\n",
      "            Conv2d-2           [-1, 64, 22, 22]           9,280\n",
      "            Conv2d-3            [-1, 256, 9, 9]         147,712\n",
      "            Linear-4                  [-1, 128]         295,040\n",
      "           Dropout-5                  [-1, 128]               0\n",
      "            Linear-6                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 452,738\n",
      "Trainable params: 452,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.68\n",
      "Params size (MB): 1.73\n",
      "Estimated Total Size (MB): 2.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "model = ConvModel(0).to(device)\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainFunction(config=None):\n",
    "\n",
    "    #initialize variables\n",
    "    model = ConvModel(config['dropout']).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    if config['optimizer'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=config['gamma'], last_epoch=-1)\n",
    "    #initialize variables end\n",
    "\n",
    "\n",
    "    #data\n",
    "    trainLoader = DataLoader(train, shuffle=True, batch_size=config['batch_size'])\n",
    "    testLoader = DataLoader(test, shuffle=True, batch_size=config['batch_size'])\n",
    "    #data end\n",
    "\n",
    "\n",
    "    wandb.watch(model, criterion, log='all')\n",
    "    y_pred_out = []\n",
    "    y_true_out = []\n",
    "\n",
    "    \n",
    "    #START\n",
    "    for epoch in range(config['epoch']):\n",
    "\n",
    "        #training variables\n",
    "        trainRunningLoss = 0.0\n",
    "        correct = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        #training loop\n",
    "        model.train()\n",
    "        for i, data in enumerate(trainLoader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            output = model(inputs.permute(0,3,1,2)) # bytter på rekkefølge til dimensjonene \n",
    "            output1 = (torch.max(output.to(device), 1)[1]) # den predictede outputtn \n",
    "            y_pred.extend(output1) # Save Prediction\n",
    "            \n",
    "            y_true.extend(labels) # Save Truth\n",
    "            loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step() # Endrer på vekten \n",
    "            \n",
    "            trainRunningLoss += loss.item() * inputs.size(0) #\n",
    "        #training loop end\n",
    "        correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "        trainAccuracy = correct / len(y_true)\n",
    "        #training variables end\n",
    "\n",
    "        #test variables\n",
    "        testRunningLoss = 0.0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        #test loop\n",
    "        model.eval()\n",
    "        for j, data in enumerate(testLoader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs.permute(0,3,1,2))# Feed Network\n",
    "\n",
    "            output1 = (torch.max(output.to(device), 1)[1])\n",
    "            y_pred.extend(output1) # Save Prediction\n",
    "            \n",
    "            y_true.extend(labels) # Save Truth\n",
    "            loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
    "            testRunningLoss += loss.item() * inputs.size(0)\n",
    "        #test loop end\n",
    "\n",
    "        correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "        testAccuracy = correct / len(y_true)\n",
    "        testRunningLoss = testRunningLoss/len(bhArray) #TODO sjekk om dette faktisk er riktig???\n",
    "        trainRunningLoss = trainRunningLoss/len(bhArray) #TODO sjekk om dette faktisk er riktig???\n",
    "\n",
    "        testRecall = recall_score(y_pred, y_true)\n",
    "        testPrecision = precision_score(y_pred, y_true)\n",
    "\n",
    "        bhAccuarcy = sum([x == y for (x, y) in zip(y_pred, y_true) if x == 0.0])/len([x for x in y_true if x == 0.0])\n",
    "        sphAccuracy = sum([x == y for (x, y) in zip(y_pred, y_true) if x == 1.0])/len([x for x in y_true if x == 1.0])\n",
    "        #test variables end\n",
    "\n",
    "        #wandb log\n",
    "        wandb.log({\"Train epoch_loss\":trainRunningLoss, \n",
    "                   \"Test epoch_loss\": testRunningLoss, \n",
    "                   \"Train accuracy\": trainAccuracy,\n",
    "                   \"Test accuracy\": testAccuracy, \n",
    "                   \"Test recall\": testRecall, \n",
    "                   \"Test precision\": testPrecision,\n",
    "                   \"BH accuracy\": bhAccuarcy,\n",
    "                   \"SPH accuracy\": sphAccuracy})\n",
    "        y_pred_out = y_pred\n",
    "        y_true_out = y_true\n",
    "        scheduler.step()\n",
    "\n",
    "        #END\n",
    "    return model, y_pred_out, y_true_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:zv22hd30) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-cloud-16</strong> at: <a href='https://wandb.ai/g13hvl2023/CNN_run/runs/zv22hd30' target=\"_blank\">https://wandb.ai/g13hvl2023/CNN_run/runs/zv22hd30</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230316_174448-zv22hd30\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:zv22hd30). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\47472\\Documents\\Skole\\Hvl\\s6\\dat191\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230316_174719-gxnxj6q2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/CNN_run/runs/gxnxj6q2' target=\"_blank\">devoted-donkey-17</a></strong> to <a href='https://wandb.ai/g13hvl2023/CNN_run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/CNN_run' target=\"_blank\">https://wandb.ai/g13hvl2023/CNN_run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/CNN_run/runs/gxnxj6q2' target=\"_blank\">https://wandb.ai/g13hvl2023/CNN_run/runs/gxnxj6q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    'epoch': 10,\n",
    "    'batch_size': 50,\n",
    "    'gamma': 1,\n",
    "    'learning_rate': 0.01,\n",
    "    'optimizer': 'adam',\n",
    "    'dropout': 0\n",
    "}\n",
    "\n",
    "# Pass the config dictionary when you initialize W&B\n",
    "run = wandb.init(project=\"CNN_run\", config=config)\n",
    "\n",
    "model, y_pred, y_true = trainFunction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\47472\\Documents\\Skole\\Hvl\\s6\\dat191\\Bachelor\\Code\\notebooks\\pyTorch\\CNN_Run.ipynb Cell 15\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/47472/Documents/Skole/Hvl/s6/dat191/Bachelor/Code/notebooks/pyTorch/CNN_Run.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m matrix_confusion \u001b[39m=\u001b[39m confusion_matrix([x\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m y_pred], [x\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m y_true])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/47472/Documents/Skole/Hvl/s6/dat191/Bachelor/Code/notebooks/pyTorch/CNN_Run.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ax\u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplot()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/47472/Documents/Skole/Hvl/s6/dat191/Bachelor/Code/notebooks/pyTorch/CNN_Run.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sns\u001b[39m.\u001b[39mheatmap(matrix_confusion, square\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBlues\u001b[39m\u001b[39m'\u001b[39m, fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m, cbar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "matrix_confusion = confusion_matrix([x.data.cpu().numpy() for x in y_pred], [x.data.cpu().numpy() for x in y_true])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(matrix_confusion, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['Mikroskopiske svarte hull', 'Sphaleroner'])\n",
    "ax.yaxis.set_ticklabels(['Mikroskopiske svarte hull', 'Sphaleroner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  [ 1.9620657 -2.279652 ] labels:  0.0\n",
      "output:  [ 0.28468692 -0.24856246] labels:  0.0\n",
      "output:  [-0.44719672  0.514661  ] labels:  1.0\n",
      "output:  [-1.2557238  1.3729163] labels:  1.0\n",
      "output:  [-0.06402051  0.3891226 ] labels:  0.0\n",
      "output:  [ 1.0150707 -1.3485805] labels:  0.0\n",
      "output:  [ 2.1881633 -2.9694524] labels:  0.0\n",
      "output:  [-1.2760706  1.3844368] labels:  1.0\n",
      "output:  [ 1.9234812 -2.8806567] labels:  0.0\n",
      "output:  [  9.470679 -11.990893] labels:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Eksempel på hva model gir som output mot labels\n",
    "testLoader = DataLoader(test, shuffle=True, batch_size=config['batch_size'])\n",
    "a = next(iter(testLoader))  \n",
    "output = model(a[0].permute(0,3,1,2))\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"output: \", output[i].data.cpu().numpy(),\"labels: \", a[1][i].data.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  0 labels:  0.0\n",
      "output:  1 labels:  1.0\n",
      "output:  0 labels:  0.0\n",
      "output:  0 labels:  0.0\n",
      "output:  0 labels:  0.0\n",
      "output:  0 labels:  1.0\n",
      "output:  1 labels:  1.0\n",
      "output:  1 labels:  1.0\n",
      "output:  1 labels:  1.0\n",
      "output:  1 labels:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Eksempel på hva model gir som output mot labels\n",
    "testLoader = DataLoader(test, shuffle=True, batch_size=config['batch_size'])\n",
    "a = next(iter(testLoader))  \n",
    "output = model(a[0].permute(0,3,1,2))\n",
    "\n",
    "list = torch.max(output.to(device), 1)[1] #Snakket om 16.03.2023, gir pred output\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"output: \", list[i].data.cpu().numpy(),\"labels: \", a[1][i].data.cpu().numpy())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9fb61b4c72117f5d7b2c8d6242145ec5a71ca8cd00b47ff0a0694a5bc1f5f2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
