{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "# Importerer spaleron og micro svarte hull data\n",
    "\n",
    "module_path = str(Path.cwd().parents[0].parents[0] / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "import trainers\n",
    "import nnmodels\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"bh\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"sph\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50, 50, 3)\n",
      "(15000, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(bhArray.shape)\n",
    "print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi slår sammen dataene for å ha et samlet datasett som kjører gjennom modellen\n",
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeler tabelle med 1 og 0 (0 = svart hull, 1 = spahleron)\n",
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75% av datasettet havner i trainData, 25% havner i testData, \n",
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gjør det om til en tensor fra numpy array. Vi gjør dette for at at dataene skal være lagret på GPU en istedet for en liste som er lagret på CPUen \n",
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor datasett \n",
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             448\n",
      "            Conv2d-2           [-1, 64, 22, 22]           9,280\n",
      "            Conv2d-3            [-1, 256, 9, 9]         147,712\n",
      "            Linear-4                 [-1, 1000]       2,305,000\n",
      "           Dropout-5                 [-1, 1000]               0\n",
      "            Linear-6                    [-1, 2]           2,002\n",
      "================================================================\n",
      "Total params: 2,464,442\n",
      "Trainable params: 2,464,442\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.69\n",
      "Params size (MB): 9.40\n",
      "Estimated Total Size (MB): 10.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "model = nnmodels.ConvModel(0).to(device)\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {\n",
    "        'goal': 'maximize', \n",
    "        'name': 'Test accuracy'\n",
    "        },\n",
    "    'parameters': {\n",
    "        'model': {'values': ['resnet34', 'resnet34Pre', 'resnet50', 'resnet50Pre']},\n",
    "        'loss': {'values': ['cross', 'hinge', 'customLoss-3', 'customLoss-4', 'customLoss-5', 'customLoss-6', 'customLoss-7']},\n",
    "        'epoch': {'values': [10]},\n",
    "        'batch_size': {'values': [50]},\n",
    "        'gamma': {'values': [1]},\n",
    "        'learning_rate': {'values': [0.01]},\n",
    "        'optimizer': {'values': ['adam', 'sgd']},\n",
    "        'dropout': {'values': [0]},\n",
    "     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper function\n",
    "def trainFunction():\n",
    "    with wandb.init(project=\"Sweep\", name=\"Sweep\") as run:\n",
    "        config = wandb.config\n",
    "\n",
    "        name_str = config['model'] + \"_\" + config['loss'] + \"_\" + config['optimizer']\n",
    "        run.name = name_str\n",
    "        \n",
    "        trainers.sweep(train, test, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: rfg5zt1x\n",
      "Sweep URL: https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nty1mhce with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: cross\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet34\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m591291\u001b[0m (\u001b[33mg13hvl2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_131133-nty1mhce</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/nty1mhce' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/nty1mhce' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/nty1mhce</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9574b6e15e41e2a5b045141e347717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.532 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.002416…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>▁▇▇▇▇█▇██▇▇</td></tr><tr><td>SPH accuracy</td><td>█▇█▇█▇▇▁▇██</td></tr><tr><td>Test accuracy</td><td>▁▇▇████▃███</td></tr><tr><td>Test epoch_loss</td><td>▂▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>Test precision</td><td>█▇█▇█▇▇▁▇██</td></tr><tr><td>Test recall</td><td>▁▆▆▇▇█▇█▇▇▆</td></tr><tr><td>Train accuracy</td><td>▁▅▇▇███▇██</td></tr><tr><td>Train epoch_loss</td><td>█▂▂▁▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.80058</td></tr><tr><td>SPH accuracy</td><td>0.97573</td></tr><tr><td>Test accuracy</td><td>0.8872</td></tr><tr><td>Test epoch_loss</td><td>0.27578</td></tr><tr><td>Test precision</td><td>0.97573</td></tr><tr><td>Test recall</td><td>0.8272</td></tr><tr><td>Train accuracy</td><td>0.91751</td></tr><tr><td>Train epoch_loss</td><td>0.20466</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/nty1mhce' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/nty1mhce</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_131133-nty1mhce\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ehqn6kwc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: cross\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet34\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_132010-ehqn6kwc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/ehqn6kwc' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ehqn6kwc' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ehqn6kwc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798ecc42edca4e5a9e11530d4aeaef1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.143343…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>▁▆▇█▇▆███▆▇</td></tr><tr><td>SPH accuracy</td><td>▂██▅▇█▂▅▁█▆</td></tr><tr><td>Test accuracy</td><td>▁▇████▇█▇▇█</td></tr><tr><td>Test epoch_loss</td><td>█▂▁▁▁▂▄▂▇▅▂</td></tr><tr><td>Test precision</td><td>▂██▅▇█▂▅▁█▆</td></tr><tr><td>Test recall</td><td>▁▆▆█▇▆███▆▇</td></tr><tr><td>Train accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>Train epoch_loss</td><td>█▄▄▃▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.88341</td></tr><tr><td>SPH accuracy</td><td>0.9086</td></tr><tr><td>Test accuracy</td><td>0.89587</td></tr><tr><td>Test epoch_loss</td><td>0.32616</td></tr><tr><td>Test precision</td><td>0.9086</td></tr><tr><td>Test recall</td><td>0.88405</td></tr><tr><td>Train accuracy</td><td>0.9796</td></tr><tr><td>Train epoch_loss</td><td>0.05215</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ehqn6kwc' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ehqn6kwc</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_132010-ehqn6kwc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xnt5tsms with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: cross\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet34Pre\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_132755-xnt5tsms</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/xnt5tsms' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/xnt5tsms' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/xnt5tsms</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87859585d4ac42f7b6783d4fe5c51de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.409 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.003140…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>█▄▆▆▅▄█▇▇▆▁</td></tr><tr><td>SPH accuracy</td><td>▁▇▇███▅▇▇██</td></tr><tr><td>Test accuracy</td><td>▁▇█▇█▇▆███▅</td></tr><tr><td>Test epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▃</td></tr><tr><td>Test precision</td><td>▁▇▇███▅▇▇██</td></tr><tr><td>Test recall</td><td>▁▇▇▇▇▇███▇▆</td></tr><tr><td>Train accuracy</td><td>▁▆▇▇█████▁</td></tr><tr><td>Train epoch_loss</td><td>▁▁▁▁▁▁▁▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.58322</td></tr><tr><td>SPH accuracy</td><td>0.92397</td></tr><tr><td>Test accuracy</td><td>0.75173</td></tr><tr><td>Test epoch_loss</td><td>7.51668</td></tr><tr><td>Test precision</td><td>0.92397</td></tr><tr><td>Test recall</td><td>0.68444</td></tr><tr><td>Train accuracy</td><td>0.74507</td></tr><tr><td>Train epoch_loss</td><td>23.83963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/xnt5tsms' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/xnt5tsms</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_132755-xnt5tsms\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x5tmu599 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: cross\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet34Pre\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_133642-x5tmu599</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/x5tmu599' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/x5tmu599' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/x5tmu599</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>█▂▃▂▂▁▃▃▄▃▁</td></tr><tr><td>SPH accuracy</td><td>▁██████████</td></tr><tr><td>Test accuracy</td><td>▁██████████</td></tr><tr><td>Test epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁██████████</td></tr><tr><td>Test recall</td><td>▁██████████</td></tr><tr><td>Train accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>Train epoch_loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.87286</td></tr><tr><td>SPH accuracy</td><td>0.95174</td></tr><tr><td>Test accuracy</td><td>0.91187</td></tr><tr><td>Test epoch_loss</td><td>0.37896</td></tr><tr><td>Test precision</td><td>0.95174</td></tr><tr><td>Test recall</td><td>0.87986</td></tr><tr><td>Train accuracy</td><td>0.98547</td></tr><tr><td>Train epoch_loss</td><td>0.03955</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/x5tmu599' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/x5tmu599</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_133642-x5tmu599\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a9kqi6rd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: cross\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_134457-a9kqi6rd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/a9kqi6rd' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/a9kqi6rd' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/a9kqi6rd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f6d64b21a04ae9a22cec40d4a1c2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.783 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.001642…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>▁▆▄▃▅▆▇▇█▄▅</td></tr><tr><td>SPH accuracy</td><td>▁▆▇███▇█▇██</td></tr><tr><td>Test accuracy</td><td>▁▆▇▇███████</td></tr><tr><td>Test epoch_loss</td><td>█▆▃▂▂▁▁▁▁▂▁</td></tr><tr><td>Test precision</td><td>▁▆▇███▇█▇██</td></tr><tr><td>Test recall</td><td>▁▇▇▇▇████▇▇</td></tr><tr><td>Train accuracy</td><td>▁▅▇▇██████</td></tr><tr><td>Train epoch_loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.85307</td></tr><tr><td>SPH accuracy</td><td>0.96414</td></tr><tr><td>Test accuracy</td><td>0.908</td></tr><tr><td>Test epoch_loss</td><td>0.22736</td></tr><tr><td>Test precision</td><td>0.96414</td></tr><tr><td>Test recall</td><td>0.86523</td></tr><tr><td>Train accuracy</td><td>0.92284</td></tr><tr><td>Train epoch_loss</td><td>0.19054</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/a9kqi6rd' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/a9kqi6rd</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_134457-a9kqi6rd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f0msmu7g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: cross\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_140053-f0msmu7g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/f0msmu7g' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/f0msmu7g' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/f0msmu7g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3e5c231f8644d88242d68b886bcb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.797 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.001612…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>▁█▇████████</td></tr><tr><td>SPH accuracy</td><td>█▁▅▄▄▅▆▂▄▁▄</td></tr><tr><td>Test accuracy</td><td>▁▇█████████</td></tr><tr><td>Test epoch_loss</td><td>█▂▁▁▁▁▁▁▁▂▂</td></tr><tr><td>Test precision</td><td>█▁▅▄▄▅▆▂▄▁▄</td></tr><tr><td>Test recall</td><td>▁▇▇██▇▇███▇</td></tr><tr><td>Train accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>Train epoch_loss</td><td>█▅▄▃▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.87022</td></tr><tr><td>SPH accuracy</td><td>0.93421</td></tr><tr><td>Test accuracy</td><td>0.90187</td></tr><tr><td>Test epoch_loss</td><td>0.29434</td></tr><tr><td>Test precision</td><td>0.93421</td></tr><tr><td>Test recall</td><td>0.87566</td></tr><tr><td>Train accuracy</td><td>0.95996</td></tr><tr><td>Train epoch_loss</td><td>0.10231</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/f0msmu7g' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/f0msmu7g</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_140053-f0msmu7g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 92yyzsqt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: cross\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet50Pre\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_141448-92yyzsqt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/92yyzsqt' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/92yyzsqt' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/92yyzsqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f9c685c90c4b8fb853626d6a0fc82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.589 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.002181…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>▁▂▅▆▇▆▇█▇██</td></tr><tr><td>SPH accuracy</td><td>▁█▅▆▄▆▅▄▆▁▃</td></tr><tr><td>Test accuracy</td><td>▁▃▅▆▇▇█████</td></tr><tr><td>Test epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁█▅▆▄▆▅▄▆▁▃</td></tr><tr><td>Test recall</td><td>▁▂▄▅▇▅▇█▇██</td></tr><tr><td>Train accuracy</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>Train epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.93194</td></tr><tr><td>SPH accuracy</td><td>0.88272</td></tr><tr><td>Test accuracy</td><td>0.9076</td></tr><tr><td>Test epoch_loss</td><td>0.22595</td></tr><tr><td>Test precision</td><td>0.88272</td></tr><tr><td>Test recall</td><td>0.92695</td></tr><tr><td>Train accuracy</td><td>0.91178</td></tr><tr><td>Train epoch_loss</td><td>0.21637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/92yyzsqt' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/92yyzsqt</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_141448-92yyzsqt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ykq8qy52 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: cross\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet50Pre\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_142925-ykq8qy52</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/ykq8qy52' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ykq8qy52' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ykq8qy52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b741d9eed042eda4e31cec33b5434b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.143389…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>▁▇███████▇█</td></tr><tr><td>SPH accuracy</td><td>▁████▇▇▇▇█▇</td></tr><tr><td>Test accuracy</td><td>▁██████████</td></tr><tr><td>Test epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁████▇▇▇▇█▇</td></tr><tr><td>Test recall</td><td>▁▇███████▇█</td></tr><tr><td>Train accuracy</td><td>▁▄▅▅▆▇▇███</td></tr><tr><td>Train epoch_loss</td><td>█▆▄▄▃▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.88789</td></tr><tr><td>SPH accuracy</td><td>0.91885</td></tr><tr><td>Test accuracy</td><td>0.9032</td></tr><tr><td>Test epoch_loss</td><td>0.32702</td></tr><tr><td>Test precision</td><td>0.91885</td></tr><tr><td>Test recall</td><td>0.88912</td></tr><tr><td>Train accuracy</td><td>0.97951</td></tr><tr><td>Train epoch_loss</td><td>0.0546</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ykq8qy52' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ykq8qy52</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_142925-ykq8qy52\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ne3s2hy4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: hinge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet34\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_144254-ne3s2hy4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/ne3s2hy4' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ne3s2hy4' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ne3s2hy4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>█▃▁▃▂▃▆▅▄▅▁</td></tr><tr><td>SPH accuracy</td><td>▁▇████▇▇█▇█</td></tr><tr><td>Test accuracy</td><td>▁▇▇████▇█▇█</td></tr><tr><td>Test epoch_loss</td><td>█▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁▇████▇▇█▇█</td></tr><tr><td>Test recall</td><td>▁▇▇▇▇▇████▇</td></tr><tr><td>Train accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>Train epoch_loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.85228</td></tr><tr><td>SPH accuracy</td><td>0.94743</td></tr><tr><td>Test accuracy</td><td>0.89933</td></tr><tr><td>Test epoch_loss</td><td>0.10195</td></tr><tr><td>Test precision</td><td>0.94743</td></tr><tr><td>Test recall</td><td>0.86254</td></tr><tr><td>Train accuracy</td><td>0.90284</td></tr><tr><td>Train epoch_loss</td><td>0.10118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ne3s2hy4' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ne3s2hy4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_144254-ne3s2hy4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 81dktcaw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: hinge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet34\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_145134-81dktcaw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/81dktcaw' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/81dktcaw' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/81dktcaw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>▁▅█▆▇██▇▇▇▇</td></tr><tr><td>SPH accuracy</td><td>▁█▅█▇▆▇▇██▇</td></tr><tr><td>Test accuracy</td><td>▁▇▇████████</td></tr><tr><td>Test epoch_loss</td><td>█▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁█▅█▇▆▇▇██▇</td></tr><tr><td>Test recall</td><td>▁▆█▇▇██▇▇▇█</td></tr><tr><td>Train accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Train epoch_loss</td><td>█▄▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.89501</td></tr><tr><td>SPH accuracy</td><td>0.90051</td></tr><tr><td>Test accuracy</td><td>0.89773</td></tr><tr><td>Test epoch_loss</td><td>0.10771</td></tr><tr><td>Test precision</td><td>0.90051</td></tr><tr><td>Test recall</td><td>0.89353</td></tr><tr><td>Train accuracy</td><td>0.94516</td></tr><tr><td>Train epoch_loss</td><td>0.05863</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/81dktcaw' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/81dktcaw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_145134-81dktcaw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 25iqw43h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: hinge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet34Pre\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_145919-25iqw43h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/25iqw43h' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/25iqw43h' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/25iqw43h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>█▁█▅▇█▇▅▆▆▇</td></tr><tr><td>SPH accuracy</td><td>▁▇▄█▆▂████▇</td></tr><tr><td>Test accuracy</td><td>▁▄▄▇▇▃█▇██▇</td></tr><tr><td>Test epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁▇▄█▆▂████▇</td></tr><tr><td>Test recall</td><td>▁▅▇▇▇█▇▇▇▇█</td></tr><tr><td>Train accuracy</td><td>▁▄▇▇█▇████</td></tr><tr><td>Train epoch_loss</td><td>█▃▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.9359</td></tr><tr><td>SPH accuracy</td><td>0.80615</td></tr><tr><td>Test accuracy</td><td>0.87173</td></tr><tr><td>Test epoch_loss</td><td>0.13132</td></tr><tr><td>Test precision</td><td>0.80615</td></tr><tr><td>Test recall</td><td>0.92484</td></tr><tr><td>Train accuracy</td><td>0.90418</td></tr><tr><td>Train epoch_loss</td><td>0.10366</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/25iqw43h' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/25iqw43h</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_145919-25iqw43h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ekz1dprk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: hinge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet34Pre\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_150808-ekz1dprk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/ekz1dprk' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ekz1dprk' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ekz1dprk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ec5deacbb74a458582ada7e4dace54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>█▂▁▂▃▂▃▂▄▁▂</td></tr><tr><td>SPH accuracy</td><td>▁██████████</td></tr><tr><td>Test accuracy</td><td>▁██████████</td></tr><tr><td>Test epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁██████████</td></tr><tr><td>Test recall</td><td>▁██████████</td></tr><tr><td>Train accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>Train epoch_loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.88605</td></tr><tr><td>SPH accuracy</td><td>0.9361</td></tr><tr><td>Test accuracy</td><td>0.9108</td></tr><tr><td>Test epoch_loss</td><td>0.13317</td></tr><tr><td>Test precision</td><td>0.9361</td></tr><tr><td>Test recall</td><td>0.88934</td></tr><tr><td>Train accuracy</td><td>0.97964</td></tr><tr><td>Train epoch_loss</td><td>0.02545</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ekz1dprk' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ekz1dprk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_150808-ekz1dprk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 21a2juf1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: hinge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_151614-21a2juf1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/21a2juf1' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/21a2juf1' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/21a2juf1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e46728a5e44dc29818d10ab2a12ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>██▄▃▆▄▅▄▆▁▄</td></tr><tr><td>SPH accuracy</td><td>▁▂██▇██████</td></tr><tr><td>Test accuracy</td><td>▁▂███████▇█</td></tr><tr><td>Test epoch_loss</td><td>▁█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁▂██▇██████</td></tr><tr><td>Test recall</td><td>▁█▇▆▇▇▇▇▇▆▇</td></tr><tr><td>Train accuracy</td><td>▂▄▇███▇█▁▅</td></tr><tr><td>Train epoch_loss</td><td>▆▃▁▁▁▁▁▁█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.84358</td></tr><tr><td>SPH accuracy</td><td>0.91939</td></tr><tr><td>Test accuracy</td><td>0.88107</td></tr><tr><td>Test epoch_loss</td><td>0.15258</td></tr><tr><td>Test precision</td><td>0.91939</td></tr><tr><td>Test recall</td><td>0.85186</td></tr><tr><td>Train accuracy</td><td>0.86116</td></tr><tr><td>Train epoch_loss</td><td>0.15711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/21a2juf1' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/21a2juf1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_151614-21a2juf1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ofy85ml1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: hinge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_153209-ofy85ml1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/ofy85ml1' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ofy85ml1' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ofy85ml1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5805aa8fdfff4c9084d3b5b929f5a506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>▁██████████</td></tr><tr><td>SPH accuracy</td><td>█▁▅▅▆▆▆▄▆▄▆</td></tr><tr><td>Test accuracy</td><td>▁▇▇████████</td></tr><tr><td>Test epoch_loss</td><td>█▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>█▁▅▅▆▆▆▄▆▄▆</td></tr><tr><td>Test recall</td><td>▁▇▇▇▇█▇████</td></tr><tr><td>Train accuracy</td><td>▁▄▅▆▇▇▇▇██</td></tr><tr><td>Train epoch_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.87154</td></tr><tr><td>SPH accuracy</td><td>0.93799</td></tr><tr><td>Test accuracy</td><td>0.9044</td></tr><tr><td>Test epoch_loss</td><td>0.10278</td></tr><tr><td>Test precision</td><td>0.93799</td></tr><tr><td>Test recall</td><td>0.87721</td></tr><tr><td>Train accuracy</td><td>0.93604</td></tr><tr><td>Train epoch_loss</td><td>0.07044</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/ofy85ml1' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/ofy85ml1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_153209-ofy85ml1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xe72cita with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: hinge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet50Pre\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_154558-xe72cita</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/xe72cita' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/xe72cita' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/xe72cita</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2815986cfddb45eca257a1f6405073ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>█▅▁▅▇▆▆▆▇▆▇</td></tr><tr><td>SPH accuracy</td><td>▁▇▃█▇█████▇</td></tr><tr><td>Test accuracy</td><td>▃▇▁▇███████</td></tr><tr><td>Test epoch_loss</td><td>█▁▃▁▁▁▁▁▁▁▁</td></tr><tr><td>Test precision</td><td>▁▇▃█▇█████▇</td></tr><tr><td>Test recall</td><td>▄▆▁▇█▇▇▇█▇█</td></tr><tr><td>Train accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>Train epoch_loss</td><td>█▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BH accuracy</td><td>0.91664</td></tr><tr><td>SPH accuracy</td><td>0.82205</td></tr><tr><td>Test accuracy</td><td>0.86987</td></tr><tr><td>Test epoch_loss</td><td>0.135</td></tr><tr><td>Test precision</td><td>0.82205</td></tr><tr><td>Test recall</td><td>0.90609</td></tr><tr><td>Train accuracy</td><td>0.91084</td></tr><tr><td>Train epoch_loss</td><td>0.09503</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/g13hvl2023/Sweep/runs/xe72cita' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/xe72cita</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230416_154558-xe72cita\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1tvpao9h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: hinge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet50Pre\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230416_160036-1tvpao9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/Sweep/runs/1tvpao9h' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/Sweep' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/sweeps/rfg5zt1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/Sweep/runs/1tvpao9h' target=\"_blank\">https://wandb.ai/g13hvl2023/Sweep/runs/1tvpao9h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [50, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"Sweep\")\n",
    "wandb.agent(sweep_id, function=trainFunction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9fb61b4c72117f5d7b2c8d6242145ec5a71ca8cd00b47ff0a0694a5bc1f5f2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
