{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bruker CNN arkitektur kombinert med PyTorch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "#other libraries\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# import random\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "#torch specific\n",
    "import torch\n",
    "import torchvision as torchv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = str(Path.cwd().parents[0].parents[0] / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "# from plotCreator import *\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"bh\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"sph\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50, 50, 3)\n",
      "(15000, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(bhArray.shape)\n",
    "print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(11*11*64, 128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x) #to activate function above\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainFunction():\n",
    "\n",
    "    #initialize variables\n",
    "    convModel = ConvModel().to(device)\n",
    "    learning_rate = wandb.config['learning_rate']\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(convModel.parameters(), lr=learning_rate)\n",
    "    #initialize variables end\n",
    "\n",
    "\n",
    "    #data\n",
    "    trainLoader = DataLoader(train, shuffle=True, batch_size=wandb.config['batch_size'])\n",
    "    testLoader = DataLoader(test, shuffle=True, batch_size=wandb.config['batch_size'])\n",
    "    #data end\n",
    "\n",
    "\n",
    "    wandb.watch(convModel, criterion, log='all')\n",
    "\n",
    "    \n",
    "    #START\n",
    "    for epoch in range(wandb.config['epochs']):\n",
    "\n",
    "        #training variables\n",
    "        trainRunningLoss = 0.0\n",
    "        correct = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        #training loop\n",
    "        convModel.train()\n",
    "        for i, data in enumerate(trainLoader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = convModel(inputs.permute(0,3,1,2))\n",
    "            output1 = (torch.max(torch.exp(output.to(device)), 1)[1])\n",
    "            y_pred.extend(output1) # Save Prediction\n",
    "            \n",
    "            y_true.extend(labels) # Save Truth\n",
    "            loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            trainRunningLoss += loss.item()\n",
    "        #training loop end\n",
    "        correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "        trainAccuracy = correct / len(y_true)\n",
    "        #training variables end\n",
    "\n",
    "        #test variables\n",
    "        testRunningLoss = 0.0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        #test loop\n",
    "        convModel.eval()\n",
    "        for j, data in enumerate(testLoader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = convModel(inputs.permute(0,3,1,2))# Feed Network\n",
    "\n",
    "            output1 = (torch.max(torch.exp(output.to(device)), 1)[1])\n",
    "            y_pred.extend(output1) # Save Prediction\n",
    "            \n",
    "            y_true.extend(labels) # Save Truth\n",
    "            loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
    "            testRunningLoss += loss.item()\n",
    "        #test loop end\n",
    "\n",
    "        correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "        testAccuracy = correct / len(y_true)\n",
    "        epochLoss = trainRunningLoss/len(bhArray)\n",
    "        #test variables end\n",
    "\n",
    "        #wandb log\n",
    "        wandb.log({\"Train epoch_loss\":epochLoss, \"Test epoch_loss\": testRunningLoss, \"Train accuracy\": trainAccuracy,\"Test accuracy\": testAccuracy})\n",
    "\n",
    "    #END\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m591291\u001b[0m (\u001b[33mg13hvl2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230224_110236-4isby5bu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/PyTorch/runs/4isby5bu' target=\"_blank\">convmodel</a></strong> to <a href='https://wandb.ai/g13hvl2023/PyTorch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/PyTorch' target=\"_blank\">https://wandb.ai/g13hvl2023/PyTorch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/PyTorch/runs/4isby5bu' target=\"_blank\">https://wandb.ai/g13hvl2023/PyTorch/runs/4isby5bu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/g13hvl2023/PyTorch/runs/4isby5bu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ca713f2340>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weights and biases set up\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    name=\"convmodel\",\n",
    "    project=\"PyTorch\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"epochs\": 50,\n",
    "    'batch_size': 100,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'name': 'sweep',\n",
    "    'metric': {\n",
    "        'goal': 'minimize', \n",
    "        'name': 'validation_loss'\n",
    "        },\n",
    "    'parameters': {\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'values': [5, 10, 15]},\n",
    "        'lr': {'max': 0.1, 'min': 0.0001}\n",
    "     }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'function' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train()\n",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(convModel\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[0;32m      8\u001b[0m \u001b[39m#initialize variables end\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[39m#data\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m trainLoader \u001b[39m=\u001b[39m DataLoader(train, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49mwandb\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     13\u001b[0m testLoader \u001b[39m=\u001b[39m DataLoader(test, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39mwandb\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[39m#data end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 344\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\utils\\data\\sampler.py:106\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement, \u001b[39mbool\u001b[39m):\n\u001b[0;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[1;32m--> 106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
      "File \u001b[1;32mc:\\Users\\student\\Anaconda3\\envs\\DAT191-gpu\\lib\\site-packages\\torch\\utils\\data\\sampler.py:114\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_samples\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# dataset size might change at runtime\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_source)\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'function' has no len()"
     ]
    }
   ],
   "source": [
    "trainFunction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT191-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75a7a58f3f8071ece7c4de206f0eb318832e927c0f5cee080ee8565c60d715a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
