{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bruker CNN arkitektur kombinert med PyTorch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "#other libraries\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# import random\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "#torch specific\n",
    "import torch\n",
    "import torchvision as torchv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importerer spaleron og micro svarte hull data\n",
    "\n",
    "module_path = str(Path.cwd().parents[0].parents[0] / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "# from plotCreator import *\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"bh\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"sph\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50, 50, 3)\n",
      "(15000, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(bhArray.shape)\n",
    "print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi slår sammen dataene for å ha et samlet datasett som kjører gjennom modellen\n",
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeler tabelle med 1 og 0 (0 = svart hull, 1 = spahleron)\n",
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75% av datasettet havner i trainData, 25% havner i testData, \n",
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gjør det om til en tensor fra numpy array. Vi gjør dette for at at dataene skal være lagret på GPU en istedet for en liste som er lagret på CPUen \n",
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor datasett \n",
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her kommer modellen inn XD \n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "\n",
    "        super(ConvModel, self).__init__()\n",
    "        # 2 cov lag blir opprette. Bildene har x, y og z verdi. \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(3*3*256, 128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x) #to activate function above\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x,3)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             448\n",
      "            Conv2d-2           [-1, 64, 22, 22]           9,280\n",
      "            Conv2d-3            [-1, 256, 9, 9]         147,712\n",
      "            Linear-4                  [-1, 128]         295,040\n",
      "            Linear-5                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 452,738\n",
      "Trainable params: 452,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.68\n",
      "Params size (MB): 1.73\n",
      "Estimated Total Size (MB): 2.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "model = ConvModel(0).to(device)\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_4704\\3561500937.py:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if config.optimizer is 'adam':\n"
     ]
    }
   ],
   "source": [
    "def trainFunction(config=None):\n",
    "\n",
    "    #init wandb\n",
    "    with wandb.init(project=\"PyTorch\", name=\"convmodel\", config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        #initialize variables\n",
    "        model = ConvModel(config.dropout).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        if config.optimizer is 'adam':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=config.gamma, last_epoch=-1)\n",
    "        #initialize variables end\n",
    "\n",
    "\n",
    "        #data\n",
    "        trainLoader = DataLoader(train, shuffle=True, batch_size=config.batch_size)\n",
    "        testLoader = DataLoader(test, shuffle=True, batch_size=config.batch_size)\n",
    "        #data end\n",
    "\n",
    "\n",
    "        wandb.watch(model, criterion, log='all')\n",
    "\n",
    "        \n",
    "        #START\n",
    "        for epoch in range(config.epoch):\n",
    "\n",
    "            #training variables\n",
    "            trainRunningLoss = 0.0\n",
    "            correct = 0\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            #training loop\n",
    "            model.train()\n",
    "            for i, data in enumerate(trainLoader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() \n",
    "                output = model(inputs.permute(0,3,1,2)) # bytter på rekkefølge til dimensjonene \n",
    "                output1 = (torch.max(output.to(device), 1)[1]) # den predictede outputtn \n",
    "                y_pred.extend(output1) # Save Prediction\n",
    "                \n",
    "                y_true.extend(labels) # Save Truth\n",
    "                loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step() # Endrer på vekten \n",
    "                \n",
    "                trainRunningLoss += loss.item() * inputs.size(0) #\n",
    "            #training loop end\n",
    "            correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "            trainAccuracy = correct / len(y_true)\n",
    "            #training variables end\n",
    "\n",
    "            #test variables\n",
    "            testRunningLoss = 0.0\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            #test loop\n",
    "            model.eval()\n",
    "            for j, data in enumerate(testLoader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                output = model(inputs.permute(0,3,1,2))# Feed Network\n",
    "\n",
    "                output1 = (torch.max(output.to(device), 1)[1])\n",
    "                y_pred.extend(output1) # Save Prediction\n",
    "                \n",
    "                y_true.extend(labels) # Save Truth\n",
    "                loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
    "                testRunningLoss += loss.item() * inputs.size(0)\n",
    "            #test loop end\n",
    "\n",
    "            correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "            testAccuracy = correct / len(y_true)\n",
    "            testRunningLoss = testRunningLoss/len(bhArray)\n",
    "            trainRunningLoss = trainRunningLoss/len(bhArray)\n",
    "            #test variables end\n",
    "\n",
    "            #wandb log\n",
    "            wandb.log({\"Train epoch_loss\":trainRunningLoss, \"Test epoch_loss\": testRunningLoss, \"Train accuracy\": trainAccuracy,\"Test accuracy\": testAccuracy})\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        #END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: t287i27q\n",
      "Sweep URL: https://wandb.ai/g13hvl2023/test/sweeps/t287i27q\n"
     ]
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {\n",
    "        'goal': 'maximize', \n",
    "        'name': 'Test accuracy'\n",
    "        },\n",
    "    'parameters': {\n",
    "        'epoch': {'values': [20]},\n",
    "        'batch_size': {'values': [50]},\n",
    "        'gamma': {'values': [0.99]},\n",
    "        'learning_rate': {'values': [0.01]},\n",
    "        'optimizer': {'values': ['adam']},\n",
    "        'dropout': {'values': [1,0]}\n",
    "     }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bhju99rf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m591291\u001b[0m (\u001b[33mg13hvl2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230309_082048-bhju99rf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/test/runs/bhju99rf' target=\"_blank\">convmodel</a></strong> to <a href='https://wandb.ai/g13hvl2023/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/test/sweeps/t287i27q' target=\"_blank\">https://wandb.ai/g13hvl2023/test/sweeps/t287i27q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/test' target=\"_blank\">https://wandb.ai/g13hvl2023/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/test/sweeps/t287i27q' target=\"_blank\">https://wandb.ai/g13hvl2023/test/sweeps/t287i27q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/test/runs/bhju99rf' target=\"_blank\">https://wandb.ai/g13hvl2023/test/runs/bhju99rf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b12b96d3824a9e8d4c1b10c0301729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.044 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.029112…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁▄▃▄▇▇█████▅▇█▇██▇▁▇</td></tr><tr><td>Test epoch_loss</td><td>▃▂▃▂▁▁▁▁▁▁▁▃▂▁▂▂▂▃█▃</td></tr><tr><td>Train accuracy</td><td>▁▃▄▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Train epoch_loss</td><td>█▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.85227</td></tr><tr><td>Test epoch_loss</td><td>0.2477</td></tr><tr><td>Train accuracy</td><td>0.96898</td></tr><tr><td>Train epoch_loss</td><td>0.14258</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">convmodel</strong> at: <a href='https://wandb.ai/g13hvl2023/test/runs/bhju99rf' target=\"_blank\">https://wandb.ai/g13hvl2023/test/runs/bhju99rf</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_082048-bhju99rf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1tuwh6ew with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230309_082717-1tuwh6ew</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/test/runs/1tuwh6ew' target=\"_blank\">convmodel</a></strong> to <a href='https://wandb.ai/g13hvl2023/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/test/sweeps/t287i27q' target=\"_blank\">https://wandb.ai/g13hvl2023/test/sweeps/t287i27q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/test' target=\"_blank\">https://wandb.ai/g13hvl2023/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/test/sweeps/t287i27q' target=\"_blank\">https://wandb.ai/g13hvl2023/test/sweeps/t287i27q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/test/runs/1tuwh6ew' target=\"_blank\">https://wandb.ai/g13hvl2023/test/runs/1tuwh6ew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bae230c94c645649dee45cfadbe84be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.044 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.029354…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁▇▆▇██▆██▇▇██▇█████▇</td></tr><tr><td>Test epoch_loss</td><td>█▃▄▃▁▁▄▁▁▂▃▁▂▃▂▃▃▃▄▅</td></tr><tr><td>Train accuracy</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>Train epoch_loss</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.83267</td></tr><tr><td>Test epoch_loss</td><td>0.24183</td></tr><tr><td>Train accuracy</td><td>0.95511</td></tr><tr><td>Train epoch_loss</td><td>0.18247</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">convmodel</strong> at: <a href='https://wandb.ai/g13hvl2023/test/runs/1tuwh6ew' target=\"_blank\">https://wandb.ai/g13hvl2023/test/runs/1tuwh6ew</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_082717-1tuwh6ew\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=trainFunction, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainFunction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT191-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75a7a58f3f8071ece7c4de206f0eb318832e927c0f5cee080ee8565c60d715a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
