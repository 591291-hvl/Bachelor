{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bruker CNN arkitektur kombinert med PyTorch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "#other libraries\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# import random\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "#torch specific\n",
    "import torch\n",
    "import torchvision as torchv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = str(Path.cwd().parents[0].parents[0] / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "# from plotCreator import *\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"bh\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"sph\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50, 50, 3)\n",
      "(15000, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(bhArray.shape)\n",
    "print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(11*11*64, 128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x) #to activate function above\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             448\n",
      "            Conv2d-2           [-1, 64, 22, 22]           9,280\n",
      "            Linear-3                  [-1, 128]         991,360\n",
      "            Linear-4                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 1,001,346\n",
      "Trainable params: 1,001,346\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.52\n",
      "Params size (MB): 3.82\n",
      "Estimated Total Size (MB): 4.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "model = ConvModel().to(device)\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainFunction(config=None):\n",
    "\n",
    "    #init wandb\n",
    "    with wandb.init(project=\"PyTorch\", name=\"convmodel\", config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        #initialize variables\n",
    "        model = ConvModel().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "        #initialize variables end\n",
    "\n",
    "\n",
    "        #data\n",
    "        trainLoader = DataLoader(train, shuffle=True, batch_size=config.batch_size)\n",
    "        testLoader = DataLoader(test, shuffle=True, batch_size=config.batch_size)\n",
    "        #data end\n",
    "\n",
    "\n",
    "        wandb.watch(model, criterion, log='all')\n",
    "\n",
    "        \n",
    "        #START\n",
    "        for epoch in range(50):\n",
    "\n",
    "            #training variables\n",
    "            trainRunningLoss = 0.0\n",
    "            correct = 0\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            #training loop\n",
    "            model.train()\n",
    "            for i, data in enumerate(trainLoader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(inputs.permute(0,3,1,2))\n",
    "                output1 = (torch.max(output.to(device), 1)[1])\n",
    "                y_pred.extend(output1) # Save Prediction\n",
    "                \n",
    "                y_true.extend(labels) # Save Truth\n",
    "                loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                trainRunningLoss += loss.item() * inputs.size(0)\n",
    "            #training loop end\n",
    "            correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "            trainAccuracy = correct / len(y_true)\n",
    "            #training variables end\n",
    "\n",
    "            #test variables\n",
    "            testRunningLoss = 0.0\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            #test loop\n",
    "            model.eval()\n",
    "            for j, data in enumerate(testLoader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                output = model(inputs.permute(0,3,1,2))# Feed Network\n",
    "\n",
    "                output1 = (torch.max(output.to(device), 1)[1])\n",
    "                y_pred.extend(output1) # Save Prediction\n",
    "                \n",
    "                y_true.extend(labels) # Save Truth\n",
    "                loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
    "                testRunningLoss += loss.item() * inputs.size(0)\n",
    "            #test loop end\n",
    "\n",
    "            correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "            testAccuracy = correct / len(y_true)\n",
    "            testRunningLoss = testRunningLoss/len(bhArray)\n",
    "            trainRunningLoss = trainRunningLoss/len(bhArray)\n",
    "            #test variables end\n",
    "\n",
    "            #wandb log\n",
    "            wandb.log({\"Train epoch_loss\":trainRunningLoss, \"Test epoch_loss\": testRunningLoss, \"Train accuracy\": trainAccuracy,\"Test accuracy\": testAccuracy})\n",
    "\n",
    "        #END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Weights and biases set up\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     name=\"convmodel\",\n",
    "#     project=\"PyTorch\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"epochs\": 50,\n",
    "#     'batch_size': 100,\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ffktxsho\n",
      "Sweep URL: https://wandb.ai/g13hvl2023/test/sweeps/ffktxsho\n"
     ]
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {\n",
    "        'goal': 'maximize', \n",
    "        'name': 'Test accuracy'\n",
    "        },\n",
    "    'parameters': {\n",
    "        'batch_size': {'values': [50]},\n",
    "        'learning_rate': {'values': [0.01]}\n",
    "     }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2tjck7n7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m591291\u001b[0m (\u001b[33mg13hvl2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\student\\Desktop\\Daniel og Sayna\\Bachelor\\Code\\notebooks\\pyTorch\\wandb\\run-20230228_160351-2tjck7n7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g13hvl2023/test/runs/2tjck7n7' target=\"_blank\">convmodel</a></strong> to <a href='https://wandb.ai/g13hvl2023/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/g13hvl2023/test/sweeps/ffktxsho' target=\"_blank\">https://wandb.ai/g13hvl2023/test/sweeps/ffktxsho</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g13hvl2023/test' target=\"_blank\">https://wandb.ai/g13hvl2023/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/g13hvl2023/test/sweeps/ffktxsho' target=\"_blank\">https://wandb.ai/g13hvl2023/test/sweeps/ffktxsho</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g13hvl2023/test/runs/2tjck7n7' target=\"_blank\">https://wandb.ai/g13hvl2023/test/runs/2tjck7n7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd575eb1fce84ca38132d3db9a16f578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.038 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.802247…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁▅▇▇██▆▇▆▆▇▄▃▇▇▅▆▅▆▆▆▂▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Test epoch_loss</td><td>▂▁▁▁▁▁▂▂▂▃▃▄▅▄▄▅▄▄▅▆▆▇▆▆▇▇▇▇▇▇▇▇████████</td></tr><tr><td>Train accuracy</td><td>▁▄▄▅▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>Train epoch_loss</td><td>█▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.83587</td></tr><tr><td>Test epoch_loss</td><td>0.66907</td></tr><tr><td>Train accuracy</td><td>1.0</td></tr><tr><td>Train epoch_loss</td><td>0.00011</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">convmodel</strong> at: <a href='https://wandb.ai/g13hvl2023/test/runs/2tjck7n7' target=\"_blank\">https://wandb.ai/g13hvl2023/test/runs/2tjck7n7</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230228_160351-2tjck7n7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=trainFunction, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainFunction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT191-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75a7a58f3f8071ece7c4de206f0eb318832e927c0f5cee080ee8565c60d715a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
